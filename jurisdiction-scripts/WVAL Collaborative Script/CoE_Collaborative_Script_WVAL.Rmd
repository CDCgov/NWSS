---
title: "Updated WVAL Methodology Collaborative Script"
author: "Bradie Ahern"
date: "`r Sys.Date()`"
output: html_document
---
# WVAL R Code Translation

- This code is maintained by CO and WA. Please each out to Kirsten Weisbeck (kirsten.weisbeck@state.co.us) or Bradie Ahern (bradie.ahern@doh.wa.gov) if there are any questions. 


NOTE: Since each jurisdiction's data looks different this code will likely need to be adjusted to fit your data needs.


## Overview: 
- This is the collaborative NWSS CoE R translation of CDC's python code to calculate wastewater viral activity level (WVAL) for SARS-CoV-2, Influenza, and RSV with the NEW updated methodology published in August 2025. 

- WVAL categorizes viral concentration into minimal, low, moderate, high, and very high to help indicate the risk of infection. 


## From CDC's methodology: 

### Calculating the Wastewater Viral Activity Level

### Major Changes: 
  - No longer using normalized data
  - Baseline lookback period is 24 months for all respiratory targets (SARS-CoV-2, Flu A, RSV)
  - Requires 8 weeks of data 
  - Biannual recalculation dates for SARS-CoV-2 changed to April 1 and October 1
  - Updated WVAL level cut off points

### Baseline Calculation:
  - For each combination of site, data submitter, PCR target, lab methods, and normalization method, a baseline is established. The “baseline” is the 10th percentile of the log-transformed concentration data within a specific time frame. Details on the baseline calculation by pathogen are below:
  
  - SARS-CoV-2
    - For site and method combinations (as listed above) with over 6 months of data, baselines are re-calculated every six calendar months (April 1st and October 1st) using the past 24 months of data.
    - For sites and method combinations with less than 6 months of data, baselines are computed every time there is a new sample until reaching six months, after which they remain unchanged until the next April 1st or October 1st, at which time baselines are re-calculated.
    
  - Influenza A and RSV
    - For site and method combinations (as listed above) with over 12 months of data, baselines are re-calculated every August 1st using all available data in the previous 24 months.
    - For sites and method combinations with less than 12 months of data, baselines are computed weekly until reaching twelve months, after which they remain unchanged until the next August 1st, at which time baselines are re-calculated.

- The standard deviation for each site and method combination is calculated using the same time frame as the baseline.

### Wastewater Viral Activity Level Calculation:
  - The number of standard deviations that each log-transformed concentration value deviates from the baseline (positive if above, negative if below) is calculated.
  - This value (x) is then converted back to a linear scale (by calculating e^x) to form the Wastewater Viral Activity Level for the site and method combination.
  - The Wastewater Viral Activity Levels from a site are averaged by week for all figures.

  - This reflects the updated cut points: 
    - Wastewater Viral Activity Level Categories for SARS-CoV-2 (https://www.cdc.gov/nwss/about-data.html#data-method, Feb 2025): 
    - The current Wastewater Viral Activity Level for each state and territory is categorized into very low, low, moderate, high, or very high as follows:
    
    SARS-CoV-2:
      - Very Low: Up to 2
      - Low: Greater than 2 and up to 3.4	
      - Moderate: Greater than 3.4 and up to 5.3	
      - High: Greater than 5.3 and up to 7.8	
      - Very High: Greater than 7.8
    
    Influenza A:
      - Very Low: Up to 2.7
      - Low: Greater than 2.7 and up to 6.2	
      - Moderate: Greater than 6.2 and up to 11.2	
      - High: Greater than 11.2 and up to 17.6	
      - Very High: Greater than 17.6
    
    RSV:
      - Very Low: Up to 2.5	
      - Low: Greater than 2.5 and up to 5.2	
      - Moderate: Greater than 5.2 and up to 8	
      - High: Greater than 8 and up to 11	
      - Very High: Greater than 11

### Aggregation for National, Regional, and State Levels:
  - We calculate the median Wastewater Viral Activity Levels among sites at national, regional, and state levels, excluding data from site/method combinations with less than 8 weeks of data for SARS-CoV-2, Influenza A, and RSV.

### Data Inclusion Criteria – SARS-COV-2, Influenza A, RSV Wastewater Viral Activity Level
  - SARS-CoV-2: New wastewater sampling sites, or sites with a substantial change in laboratory methods are included in national, regional, state, or territorial median values once there are at least 8 weeks of samples reported for that location.
  - Influenza A and RSV: New wastewater sampling sites, or sites with a substantial change in laboratory methods, are included in national and state or territorial median values beginning on August 1st of each year once there are at least 8 weeks of samples reported for that pathogen. Data must be reported by October 1st of that year to be included in national and state or territorial median values for that respiratory virus season. If data are reported after October 1st of that year, they will not be displayed until August 1st of the following year.

## Data Needs

### Input Data
      - 1CDP downloaded MLM analytics file OR 
      - Raw data from your jurisdiction 
  
  - Dataset Variables Needed (using 1CDP-ready column names)
      - wwtp_jurisdiction
      - source: the source of the data submitted to 1CDP (NWSS, WWS, CDC)
      - lab_id: ID assigned to the testing lab
      - site_id: site ID 
      - wwtp_name: name of wastewater treatment facility sample collection location
      - population_served: sewershed population
      - pcr_target: pathogen (sars-cov-2, fluav, rsv)
      - pcr_gene_target: specific pathogen gene target being tested (i.e., n for SARS-CoV-2)
      - pcr_target_avg_conc: SARS-CoV-2 raw concentration in gene copies/L
      - lod_sewage: limit of detection
      - county_names: county containing wastewater treatment facility sample collection location
      - concentration_method: method used to concentrate the sample prior to analysis of the concentrate
      - extraction_method: method used for nucleic acid extraction from the sample
      - major_lab_method: A number used to distinguish major lab methods at the reporting jurisdiction level
      - sample_location: Sample collection location in the wastewater system, whether at a wastewater treatment plant or upstream in the wastewater system.
      - sample_location_specify: If 'sample_location' is "upstream", specify the collection location in the wastewater system; an arbitrary name may be used if you do not wish to disclose the real name. 
      - sample_matrix: Wastewater matrix from which the sample was collected.
      
  - NOTE: make sure the pcr_target for all sars-cov-2 data is 'sars-cov-2'
      

## Depdencies
 - Libraries: pacman, tidyverse, lubridate, here, REDCapR, sf, zoo, ggformula, slider, stringr, ggplot2
      
## Compare your jurisdiction's data to CDC's
  - The last function allows you to compare your WVAL results to CDC's WVAL results and find any discordance. 
  - Some jurisdictions found better concordance when line 522 (currently commented out) was included

## Security
  - Never store sensitive data including passwords and tokens in your code or wastewater datasets in GitHub.
  - If you suspect that sensitive data has been exposed, please notify the maintainers immediately.
  

## Load dependencies
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load libraries
library(pacman)
p_load(tidyverse, lubridate, here, REDCapR, sf, zoo, ggformula, slider, stringr, ggplot2)
```

```{r prep jurisdiction data for wval}

# juris_dataset <- read_csv("file_path.csv")

# INSERT JURISDICTION SPECIFIC INFORMATION IN THIS SECTION 
# Prep the data
data <- juris_dataset %>%
    # ***Optional code (not necessary if your columns already match 1CDP data)
    # rename variables to match dcipher/1CDP code
    # rename(
    #   site_id = sample_site_id, 
    #   source = funding,
    #   lab_id = micro_lab_name,
    #   wwtp_name = sample_site_name,
    #   population_served = totalpop,
    #   county_names = county
    # ) %>%
  # Convert sample_collect_date to date  
  mutate(sample_collect_date = as.Date(lubridate::parse_date_time(sample_collect_date, orders = c("mdY", "Ymd")))) %>%
  
  # Set pcr_target and pcr_gene_target to lowercase to avoid case issues later in the script
  mutate(pcr_target = tolower(pcr_target),
         pcr_gene_target = tolower(pcr_gene_target)) %>%
  
  #Create key_plot_with_pcr_by_day- see Function for prioritizing SARS-CoV-2 gene targets for more information
  mutate(key_plot_with_pcr_by_day = paste(wwtp_jurisdiction, wwtp_name, sample_location, sample_location_specify, sample_matrix, pcr_target, sample_collect_date,  sep = "_")) %>% 

  # Filter for the respiratory virus targets that are validated for WVAL
  filter(pcr_target %in% c("fluav", "rsv", "sars-cov-2")) %>%
  select(wwtp_jurisdiction, 
         source, 
         #data_source_short, 
         #data_source, 
         lab_id, 
         site_id, 
         wwtp_name, 
         population_served,
         sample_id,
         sample_collect_date, 
         pcr_target,
         pcr_gene_target, 
         pcr_target_avg_conc, 
         lod_sewage, 
         county_names,     
         concentration_method, 
         extraction_method, 
         major_lab_method, 
         key_plot_with_pcr_by_day) %>%
  filter(!is.na(pcr_target_avg_conc))
```


## Sars-cov-2 Adjustments
```{r Sars-cov-2 Adjustments}
  ##########################################################
  # Function for prioritizing SARS-CoV-2 gene targets
  ##########################################################
  # CDC guidance states that if multiple assays are used to quantify sars-cov-2 at the same sampling site on the same day, only some of those measurements may be used in the aggregated value. 
  # This hierarchy is based on which genes tend to yield the highest wastewater concentrations in peer-reviewed literature, and is as follows: N targets, OR targets, E targets, RDRP targets, S targets (non-TaqPath), TaqPath S target
  # Sars-cov-2 data is filtered based on the hierarchy to keep only the rows for the gene target that is the highest on the list. 
  # CDC runs this through their MLM Analytic pipeline so the index or key is different than the WVAL pipeline 
  # Key/ Index: key_plot_with_pcr_by_day: Composite key for a sampling site based on 'wwtp_jurisdiction', 'wwtp_name', 'sample_location',  'sample_location_specify',  'sample_matrix', 'pcr_target', 'date'. If the sampling site is managed by WastewaterSCAN or a CDC commercial contractor, it will start with 'WWS' or 'CDC'

  prioritize_sars_targets <- function(data) {
    
    dt <- data.table(data)
    non_sarscov2_dt <- dt[pcr_target != "sars-cov-2",]
    sarscov2_dt <- dt[pcr_target == "sars-cov-2",]
  
    #Create new column that ranks sars-cov-2 gene targets 
    sarscov2_dt[, gene_rank := fcase(
      pcr_gene_target == "n", 1,
      grepl("n1|n2|n3|n1 and n2 combined|ddcov_n", pcr_gene_target, ignore.case = TRUE), 1,
      grepl("orf1", pcr_gene_target, ignore.case = TRUE), 2,
      grepl("e_sarbeco|ddcov_e", pcr_gene_target, ignore.case = TRUE), 3,
      grepl("rdrp", pcr_gene_target, ignore.case = TRUE), 4,
      pcr_gene_target == "s", 5,
      grepl("taqpath s", pcr_gene_target, ignore.case = TRUE), 6,
      default = 99)
      ]
    # Keep only the lowest ranking sars-cov-2 gene targets 
    sarscov2_dt <- sarscov2_dt[, .SD[gene_rank == min(gene_rank, na.rm = T)], # keep lowest ranked gene per group
                               by = .(key_plot_with_pcr_by_day)] #OR use by = site_id, sample_collect_date, pcr_target
    sarscov2_dt[, gene_rank := NULL]
    
    data <- as.data.frame(rbind(non_sarscov2_dt, sarscov2_dt))
  }

  ##########################################################
  # Function for handling n1/n2 geometric mean to mimic CDC
  ##########################################################
  # CDC calculates a geometric mean of samples for the same pcr_target from the same site/day/MLM
  # This function applies for sars-cov-2 samples from the same sample ID but different gene targets
  # Results below the LOD are replaced with the geometric mean of LOD/2 for the samples
  # LOD sewage for both n1/n2 should be the same, so geometric mean of LOD/2 is just LOD/2
  calc_n1n2_avg <- function(data) {
    
    samples_with_both <- data %>%
    # identify sample IDs that have BOTH n1 and n2
    # filter to sars n1/n2 gene targets
    filter(pcr_target == 'sars-cov-2', 
           pcr_gene_target %in% c('n1', 'n2')) %>%
    # group by sample info/date/lab/method
    group_by(sample_id) %>%
    summarise(n_gene_targets = n_distinct(pcr_gene_target), .groups = 'drop') %>%
    filter(n_gene_targets == 2) %>%
    pull(sample_id)
  
    # process samples with BOTH n1 and n2 and calculate geometric mean of them
    sars_averaged <- data %>%
    # filter to samples with both n1 and n2 with same sample ID 
    filter(sample_id %in% samples_with_both) %>%
    group_by(sample_id) %>%
    # calculate intermediate values
    reframe(
      # average LOD across n1 and n2
       avg_lod = mean(lod_sewage, na.rm = TRUE),
      
      # count how many values are above LOD
      n_above_lod = sum(pcr_target_avg_conc >= lod_sewage, na.rm = TRUE),
      
      # calculate the geometric mean of the n1/n2 concentrations, else set to LOD/2
      pcr_target_avg_conc = if_else(
        n_above_lod > 0,
        10^(mean(log10(pcr_target_avg_conc), na.rm = TRUE)),
         avg_lod / 2
      ),
      
      # update lod_sewage to averaged value
      lod_sewage = avg_lod,
      
      # create pcr_gene_target_agg variable to match CDC nwss
      pcr_gene_target_agg = 'n2 and n1'
    ) %>%
    
    ungroup() %>%
    
    # keep only one row per sample (remove the duplicate N1/N2 rows)
    distinct(sample_id, .keep_all = TRUE) %>%
    
    # remove intermediate calculation columns
    select(-avg_lod, -n_above_lod)
    
  # get samples with only individual results (keep all other samples as is)
    sars_individual <- data %>%
      filter(!sample_id %in% samples_with_both) %>%
      mutate(pcr_gene_target_agg = pcr_gene_target)
    
  # combine averaged and individual results
  final_result <- bind_rows(sars_averaged, sars_individual)
  
  return(final_result)
  }


# Call the functions
data <- data %>% 
  # prioritize sars-cov-2 gene targets
  # *** Only run this if your jurisdiction tests (or ever tested) for multiple sars-cov-2 gene targets
  prioritize_sars_targets %>%
  # process n1/n2 sars-cov-2 data
  # *** Only run this if it applies to your jurisdiction
  calc_n1n2_avg %>% 
```


## Helper functions
```{r Helper functions}
  #################################################
  # Quantile approximation to mimic PySpark
  #################################################
  quantile_approx <- function(x, p) {
  x <- sort(x)
  if (!length(x) || all(is.na(x))) return(NA_real_)
  if (p >= 1) return(x[length(x)])
  i_x <- p * (length(x) - 1) + 1
  x[floor(i_x)]
  }

  ################################################################
  # Functions for calculating days to nearest recalculation target
  ################################################################
  # Baseline recalculates on April 1st and Oct 1st of every year for sars-cov-2
  # Baseline recalculates on August 1st of every year for FLUAV/RSV
  # These functions create a variable that is a count of the number of days to nearest recalculation date
  # Use before baseline calculations

  # Days to nearest Apr 1 / Oct 1 (SARS-CoV-2)
  calc_days_to_target_sars <- function(date) {
  date    <- as.Date(date)
  y       <- year(date)
  april_1 <- as.Date(sprintf("%d-04-01", y))
  oct_1   <- as.Date(sprintf("%d-10-01", y))
  m <- month(date)
  if (m >= 4 && m <= 9) abs(as.integer(difftime(date, april_1, units = "days")))
  else                  abs(as.integer(difftime(date, oct_1,   units = "days")))
  }

  # Days to nearest Aug 1 (FLU/RSV)
  calc_days_to_target_flu_rsv <- function(date) {
  date <- as.Date(date)
  y    <- year(date)
  aug1 <- as.Date(sprintf("%d-08-01", y))
  augN <- as.Date(sprintf("%d-08-01", y + 1))
  pmin(abs(as.integer(difftime(date, aug1, units = "days"))),
       abs(as.integer(difftime(date, augN, units = "days"))))
  }
  
  ##################################################
  ## Function for creating key for plots
  ## Use if applicable to your jurisdiction
  ##################################################
  # Key for plots: jurisdiction-name-location-matrix-mlm (dash-separated)
  make_key_plot_with_pcr <- function(df) {
  kp <- paste(
    coalesce(tolower(df$wwtp_jurisdiction), ""),
    coalesce(tolower(df$wwtp_name), ""),
    coalesce(df$sample_location, ""),
    coalesce(df$sample_matrix, ""),
    coalesce(as.character(df$major_lab_method), ""),
    sep = "-"
  )
  kp <- str_replace_all(kp, "-{2,}", "-")
  kp <- str_replace_all(kp, "^-+|-+$", "")
  kp
  }

  ##################################################
  ## Function for handling outliers
  ##################################################
  # Function to remove outliers with z-score > 4
  # data - the pre-processed ww data containing the site_id_with_pcr_source_mlm
  # and pcr_target_avg_conc_ln
  # The output is a df with outliers removed
  
  remove_outliers <- function(data) {
    ## calculate mean and standard deviation for each site_lab_norm combo
    mean_std_ln <- data %>%
      group_by(site_id_with_pcr_source_mlm) %>%
        summarise(
        mean_avg_conc_ln = mean(pcr_target_avg_conc_ln, na.rm = TRUE),
        stddev_avg_conc_ln = sd(pcr_target_avg_conc_ln, na.rm = TRUE)) 
    
    clean_df <- left_join(data, mean_std_ln, by = "site_id_with_pcr_source_mlm")
    
    # set z-score threshold
    z_score_threshold <- 4
    
    ## calculate and filter the Z-score, handling NA stddev and division by zero
    clean_df <- clean_df %>%
      mutate(z_score = ifelse((is.na(stddev_avg_conc_ln) | stddev_avg_conc_ln == 0), 0, ### assign a z-score to ensure rows won't be removed
                                     abs(pcr_target_avg_conc_ln - mean_avg_conc_ln) / stddev_avg_conc_ln))
    
    ## store outliers
    outliers <- clean_df %>%
      filter(z_score > z_score_threshold)
    
    ## filter out outliers based on the z-score threshold
    clean_df <- clean_df %>% 
      filter((z_score <= z_score_threshold) | is.na(z_score)) %>%
      select(-mean_avg_conc_ln, -stddev_avg_conc_ln, -z_score)
    return(clean_df)
  }

  ##################################################
  ## Function for categorizing wval 
  ##################################################
  # This function categorizes wastewater index values into wastewater viral activity levels by pathogen
  # The current Wastewater Viral Activity Level for each state and territory is categorized into very low, low, moderate, high, or very high as follows:
  # SARS-CoV-2:
  # Very Low: Up to 2
  # Low: Greater than 2 and up to 3.4	
  # Moderate: Greater than 3.4 and up to 5.3	
  # High: Greater than 5.3 and up to 7.8	
  # Very High: Greater than 7.8
 
  # Influenza A:
  # Very Low: Up to 2.7
  # Low: Greater than 2.7 and up to 6.2	
  # Moderate: Greater than 6.2 and up to 11.2	
  # High: Greater than 11.2 and up to 17.6	
  # Very High: Greater than 17.6
  
  # RSV:
  # Very Low: Up to 2.5	
  # Low: Greater than 2.5 and up to 5.2	
  # Moderate: Greater than 5.2 and up to 8	
  # High: Greater than 8 and up to 11	
  # Very High: Greater than 11 
  
  categorize_wval <- function(ww_index, target) {
  t <- tolower(target)
  out <- rep(NA_character_, length(ww_index))
  
  is_sars <- stringr::str_detect(t, "sars")
  is_flu  <- stringr::str_detect(t, "fluav")
  is_rsv  <- stringr::str_detect(t, "rsv")
  
  out[is_sars] <- as.character(cut(
    ww_index[is_sars],
    breaks = c(-Inf, 2.0, 3.4, 5.3, 7.8, Inf),
    labels = c("Very Low", "Low", "Moderate", "High", "Very High"),
    right  = TRUE
  ))
  
  out[is_flu] <- as.character(cut(
    ww_index[is_flu],
    breaks = c(-Inf, 2.7, 6.2, 11.2, 17.6, Inf),
    labels = c("Very Low", "Low", "Moderate", "High", "Very High"),
    right  = TRUE
  ))
  
  out[is_rsv] <- as.character(cut(
    ww_index[is_rsv],
    breaks = c(-Inf, 2.5, 5.2, 8, 11, Inf),
    labels = c("Very Low", "Low", "Moderate", "High", "Very High"),
    right  = TRUE
  ))
  
  out
  }

```


## Function for generating WVAL for sars-cov-2, FLU A, RSV
```{r wval function}
wval_v2 <- function(data, target) { 
  
  # prepare dataset and apply filters
  all_final <- data %>% 
    # filter to pcr target and populations over 3000
    filter(pcr_target == target & population_served >= 3000) %>% 

    # create dummy variable for below LOD yes/no
    mutate(
      pcr_target_below_lod = if_else(pcr_target_avg_conc < lod_sewage, 'yes', 'no'),
      # pcr target detection yes/no
      pcr_target_detect = if_else(pcr_target_avg_conc < lod_sewage, 'no', 'yes'),
      # if target avg concentration is below LOD, set to 1/2*LOD
      # otherwise leave as is
      pcr_target_avg_conc_lin = if_else(pcr_target_below_lod == 'yes',
                                         lod_sewage/2, 
                                         pcr_target_avg_conc),
      # take the log10 of the target avg concentration
      pcr_target_avg_conc_log10 = if_else(pcr_target_below_lod == 'yes',
                                           log10(lod_sewage/2),
                                           log10(pcr_target_avg_conc_lin)),
      # calculate natural log of linear avg conc
      pcr_target_avg_conc_ln = log(pcr_target_avg_conc_lin),
      # calculate year
        year = year(sample_collect_date)
    )
  
  all_final1 <- all_final %>%
        # ***Uncomment these next lines if they are applicable to your jurisdiction
                      # filter(institution_type == "not institution specific",
                  # dashboard_ignore == "no",
                # mlm_adjusted == "No",
                  # pcr_target_detect !="") %>%
   #  filter(mlm_adjusted == "Yes" | mlm_adjusted == "" | is.na(mlm_adjusted)) %>%
      # Create norm_method column
    group_by(site_id, source, major_lab_method) %>%
    arrange(desc(sample_collect_date), .by_group = TRUE) %>%
    # finding gaps in major lab method and identifying them
    mutate(sample_collect_date = as.Date(sample_collect_date),
           date_diff = as.numeric(abs(sample_collect_date - lag(sample_collect_date))),
           is_gap_start = case_when(is.na(date_diff) ~ 0,
                                    date_diff <= 365 ~ 0,
                                    date_diff >365 ~ 1),
           cumsum_gaps = cumsum(na.omit(is_gap_start)),
           major_lab_method = as.numeric(major_lab_method),
           mlm_increment = if_else(cumsum_gaps > 0, cumsum_gaps*0.1, 0),
           major_lab_method = if_else(cumsum_gaps > 0, major_lab_method + mlm_increment,
                                                              major_lab_method)) %>%
             ungroup() %>%
    select(-date_diff, -is_gap_start, -cumsum_gaps, -mlm_increment) %>%
    drop_na(site_id) %>%
    drop_na(sample_collect_date) %>%
    drop_na(population_served) %>%
    
    # add new column that combines site_id and pcr_target
      mutate(
      site_id_with_pcr = paste(site_id, pcr_target, sep = "_"),
    # add new column that combines site_id, pcr_target, source
      site_id_with_pcr_source = paste(site_id, pcr_target, source, sep = "_"),
    # add new column that combines site_id, pcr_target, source, and major lab method
      site_id_with_pcr_source_mlm = paste(site_id_with_pcr, source, major_lab_method, sep = "_")) %>%
    
    #Group by site_id_with_pcr_source_mlm 
    # *** Some jurisdictions may need this group_by line, if you are seeing a lot of discordant results try to uncomment this line
    #group_by(site_id_with_pcr_source_mlm) %>% 
    
    # calculate days since first sample and first sample collection date
    mutate(
      days_since_first_sample = as.integer(difftime(sample_collect_date, min(sample_collect_date), units = "days")),
      first_collection_date = min(sample_collect_date)) %>%
    ungroup()
  
  # remove outliers function call
  all_final2 <- remove_outliers(data=all_final1)

  
  #####################################################
  # Calculating days to nearest recalculation target
  #####################################################
  
  # create dataframe with days to nearest target variables based on pathogen type
  if(target == 'sars-cov-2'){
  all_final3 <- all_final2 %>% 
  # fill in missing sample dates
    arrange(sample_collect_date, .by_group = TRUE) %>%
    complete(sample_collect_date = seq.Date(min(sample_collect_date, na.rm = TRUE),
                                            max(sample_collect_date, na.rm = TRUE),
                                            by = 'day')) %>%
    # days to nearest target for sars-cov-2 based on april and october recalculation dates
    mutate(half_year = if_else(month(sample_collect_date) >= 4 & month(sample_collect_date) <= 9, 1, 2),
           year = year(sample_collect_date),
           days_to_nearest_target = sapply(sample_collect_date, calc_days_to_target_sars)) %>%
   group_by(site_id_with_pcr_source_mlm, half_year, year) %>%
    # calculate minimum days to target for sars-cov-2
    mutate(min_days_to_target = min(days_to_nearest_target, na.rm = TRUE)) %>% 
    ungroup() %>%
    # drop helper variable
      select(-half_year)
  
    # influenza A and RSV recalculate on august 1
  } else {
    # calculate days to nearest target for flu/rsv
  all_final3 <- all_final2 %>%
    # fill in missing sample dates
    arrange(sample_collect_date, .by_group = TRUE) %>%
    complete(sample_collect_date = seq.Date(min(sample_collect_date, na.rm = TRUE),
                                            max(sample_collect_date, na.rm = TRUE),
                                            by = 'day')) %>%
    mutate(year_val = year(sample_collect_date),
    # days to nearest august 1st recalculation target date
           days_to_nearest_target = sapply(sample_collect_date, calc_days_to_target_flu_rsv)) %>%
    group_by(site_id_with_pcr_source_mlm, year_val) %>%                       
    mutate(min_days_to_target = min(days_to_nearest_target, na.rm = TRUE)) %>%
    ungroup()
    }
  
  ##################################################
  ## Baseline Calculation
  ##################################################
  # Calculate baseline (10th percentile) and standard deviation for last 24 months 
  # First 6 months or since the nearest to Apr 1/Oct 1 for sars-cov-2
  # First 12 months or since nearest Aug 1st for FLU A/RSV
  # Input dataset with outliers removed
  # create half year - specific to SARS
  # Output dataset with baseline, sd, and half year variables
  
  if(target == "sars-cov-2") {
    all_final4 <- all_final3 %>%
    group_by(site_id_with_pcr_source_mlm) %>%
    mutate(baseline_flag = (days_since_first_sample <= 182) | (days_to_nearest_target == min_days_to_target), 
          temp_baseline = if_else(
                        baseline_flag,
                        slide_index_dbl(pcr_target_avg_conc_ln, sample_collect_date,
                        .before = 730, .after = 0, .complete = FALSE,
                        .f = ~ quantile_approx(.x, 0.10)),
                        NA_real_
                        ),
        baseline_avg_conc_ln = na.locf(temp_baseline, na.rm= FALSE),
        temp_std = if_else(
                    baseline_flag,
                    slide_index_dbl(pcr_target_avg_conc_ln, sample_collect_date,
                    .before = 730, .after = 0, .complete = FALSE,
                    .f = ~ sd(.x, na.rm = TRUE)),
                    NA_real_
                        ),
      std_avg_conc_ln = na.locf(temp_std, na.rm = FALSE)
    ) %>%
  select(-c(temp_std, temp_baseline, baseline_flag)) %>%
  drop_na(pcr_target) %>%
      ungroup()
  } else {
    all_final4 <- all_final3 %>%
    group_by(site_id_with_pcr_source_mlm) %>%
    mutate(baseline_flag = (days_since_first_sample <= 365) | (days_to_nearest_target == min_days_to_target) &
          (month(sample_collect_date) %in% 8:12),
          temp_baseline = if_else(
                        baseline_flag,
                        slide_index_dbl(pcr_target_avg_conc_ln, sample_collect_date,
                        .before = 730, .after = 0, .complete = FALSE,
                        .f = ~ quantile_approx(.x, 0.10)),
                        NA_real_
                        ),
      baseline_avg_conc_ln = na.locf(temp_baseline, na.rm = FALSE),
      temp_std = if_else(
                baseline_flag,
                slide_index_dbl(pcr_target_avg_conc_ln, sample_collect_date,
                        .before = 730, .after = 0, .complete = FALSE,
                        .f = ~ sd(.x, na.rm = TRUE)),
                NA_real_
                ),
              std_avg_conc_ln = na.locf(temp_std, na.rm = FALSE)
              ) %>%
    select(-temp_baseline, -temp_std, -baseline_flag) %>%
    drop_na(pcr_target) %>%
    ungroup()
  }
        
  # saving last calculated baseline and standard deviation
    last_vals <- all_final4 %>%
      filter(!is.na(std_avg_conc_ln) & !is.na(baseline_avg_conc_ln)) %>%
      group_by(site_id_with_pcr_source_mlm) %>%
      slice_tail(n = 1) %>%
      summarise(
        last_baseline_ln = baseline_avg_conc_ln,
        last_std_ln = std_avg_conc_ln
      )
    
  #################################################
  # Calculate wastewater index values
  #################################################

  # create result dataframe and join last calculated baseline/standard deviation
    result <- all_final4 %>%
      left_join(last_vals, by = "site_id_with_pcr_source_mlm") %>%
      group_by(site_id_with_pcr_source_mlm) %>%
  # create variable for the number of days that site has been active
      mutate(
        days_site_online = max(days_since_first_sample, na.rm = TRUE)) %>% 
      ungroup() %>% 
  # create wastewater index variables, excluding sites that have been online for less than 56 days for sars-cov-2   
    mutate(
      ww_index_ln = case_when(
          days_site_online < 56 ~ NA_real_, TRUE ~ (pcr_target_avg_conc_ln - last_baseline_ln) / last_std_ln),
      ww_index_ln_lin = exp(ww_index_ln),
  # create day of week and week end variables
      day_of_week = wday(sample_collect_date),
      week_end = sample_collect_date + days(7-day_of_week)
      ) %>%
      group_by(site_id_with_pcr_source_mlm, week_end) %>%
      arrange(sample_collect_date, .by_group = TRUE) %>%
      ungroup() %>%
      distinct()
    
  # create intermediate dataset
  intermediate_result <<- result


  ##################################################
  ## MLM Overlap Handling
  ##################################################
  # if a site_id_with_pcr has more than one MLM reporting in a week,
  # keep data only if ww_index_ln_lin is non-null and it is from a more recent MLM
    result <- result %>%
    group_by(site_id_with_pcr_source_mlm) %>%
    mutate(min_sample_date_for_mlm = min(sample_collect_date, na.rm = TRUE)) %>%
    ungroup() %>%
  # determines latest min_sample_date_for_mlm across all site_id_with_pcr_source_mlm
  # that share the same site_id_with_pcr_source
  # using rank descending in case of a situation where these min dates happen to be the same (in which case they will both be 1)
    group_by(site_id_with_pcr, week_end) %>%
    arrange(desc(min_sample_date_for_mlm), desc(major_lab_method)) %>%
    mutate(latest_min_date_rank = rank(-as.numeric(min_sample_date_for_mlm), ties.method = "min")) %>%
    ungroup() %>%
    
  # filter to retain only rows from the latest site_id_with_pcr_source_mlm with non-null ww_index_ln_lin
    filter(latest_min_date_rank == 1, !is.na(ww_index_ln_lin))
  
  
  #################################################
  # Categorize WVAL
  #################################################
  # at the result level
  unaggregated_result <- result %>%
            mutate(wval_result = categorize_wval(ww_index_ln_lin, pcr_target)) %>% distinct()
  
  unaggregated_result <<- unaggregated_result
  
  
  
  #################################################
  # Calculate the site weekly average for WVAL 
  #################################################
  # function for aggregating by week, site, and target
  # creates categories for categorizing pathogen ww index values
  site_weekly_average <- function(data) {
        site_ag <- data %>%
      # remove NA ww_index_ln_lin, arrange by sample_collect_date and group by site and week
          filter(!is.na(ww_index_ln_lin)) %>%
          arrange(desc(sample_collect_date)) %>%
          group_by(site_id_with_pcr, week_end) %>%
      
          reframe(
            site_id = first(site_id),
            mean_pcr_target_avg_conc_lin = mean(pcr_target_avg_conc_lin, na.rm = TRUE),
            all_pcr_target_avg_conc_lin = paste(pcr_target_avg_conc_lin, collapse = ", "),
            wval_site_wk = mean(ww_index_ln_lin, na.rm = TRUE),
            all_sample_collect_dates = paste(sample_collect_date, collapse = ", "),
            days_since_first_sample = last(days_since_first_sample),
            baseline_avg_conc_ln  = last(baseline_avg_conc_ln),
            last_baseline_ln = last(last_baseline_ln),
            last_std_ln = last(last_std_ln),
            std_avg_conc_ln = last(std_avg_conc_ln),
            pcr_target_below_lod = first(pcr_target_below_lod),
            pcr_target = first(pcr_target),
            all_ww_index_ln_lin = paste(ww_index_ln_lin, collapse = ", "),
            #all_sample_ids = paste(sample_id, collapse = ", "),
            source = source,
            county_names = county_names
          ) %>% 
      # categorize wval
        mutate(wval_site_wk_level = categorize_wval(wval_site_wk, pcr_target)
        )%>% distinct()
  }

            
  ############################
  ## Return aggregated results 
  ############################            
    
  site_ag <- site_weekly_average(unaggregated_result)
  
  return(site_ag)
  
  }
  
  ### NEW FUNCTION FOR COUNTY LEVEL
  # Calculates the WVAL for the county level aggregation
  # takes the median of the site-week aggregated WVALs in a county
  # data - data must contain site-week aggregated WVAL values
  # Outputs a df containing county-week aggregated WVAL values  
  wval_county_wk_agg <- function(data) {
  # aggregate by county 
  county_ag <- data %>% 
    # group by county and week and target
    group_by(county_names, week_end, pcr_target) %>%
    # aggregate
    reframe(week_end = first(week_end),
            wval_county_wk = median(wval_site_wk)
    ) %>%
    unique() %>%
    arrange(county_names, week_end) %>% ungroup()
  
  
  # calculate wval categories
  county_ag <- county_ag %>%
            mutate(wval_county_wk_level = categorize_wval(wval_county_wk, pcr_target))
  
  return(county_ag)
  }
```


```{r Call wval functions}
  #######################################
  ## Call site and county wval functions 
  #######################################  
  
  site_ag_sars <- wval_v2(data, target = 'sars-cov-2')
  site_ag_flu <- wval_v2(data, target = "fluav")
  site_ag_rsv <- wval_v2(data, target = "rsv")

  county_ag_sars <- wval_county_wk_agg(data=site_ag_sars)
  county_ag_flu <- wval_county_wk_agg(data=site_ag_flu)
  
  #######################################
  ## Create State WVAL 
  ####################################### 
  state_wval_sarscov2 <- site_ag_sars %>%
    group_by(week_end) %>%
    mutate(state_wval = median(wval_site_wk, na.rm = T)) %>%
    mutate(state_level = categorize_wval(state_wval, pcr_target))%>%
    distinct(week_end, state_wval, state_level)
  
  state_wval_flu <- site_ag_flu %>%
    group_by(week_end) %>%
    mutate(state_wval = median(wval_site_wk, na.rm = T)) %>%
    mutate(state_level = categorize_wval(state_wval, pcr_target))%>%
    distinct(week_end, state_wval, state_level)
  
  state_wval_rsv <- site_ag_rsv %>%
    group_by(week_end) %>%
    mutate(state_wval = median(wval_site_wk, na.rm = T)) %>%
    mutate(state_level = categorize_wval(state_wval, pcr_target))%>%
    distinct(week_end, state_wval, state_level)
```


## Comparing CDC NWSS data with your jurisdictions data
```{r}
# function to compare wval levels with concordance analysis
compare_wval_function <- function(state_wval, nwss_wval, print_matches = TRUE) {
    # convert wval variables to factors and designate order 
    state_wval <- factor(state_wval, levels = c("Very Low", "Low", "Moderate", "High", "Very High"), ordered=TRUE)
    nwss_wval <- factor(nwss_wval, levels = c("Very Low", "Low", "Moderate", "High", "Very High"), ordered=TRUE)
    
    # check if lengths match
    if (length(state_wval) != length(nwss_wval)) {
        stop("Variables must have the same length")
    }
    
    # create comparison data frame
    comparison_df <- data.frame(
        state_wval = state_wval,
        nwss_wval = nwss_wval,
        Match = state_wval == nwss_wval
    )
    
    # calculate summary statistics
    total_obs <- nrow(comparison_df)
    matching_obs <- sum(comparison_df$Match)
    non_matching_obs <- total_obs - matching_obs
    match_percentage <- (matching_obs / total_obs) * 100
    discordance_percentage <- (non_matching_obs / total_obs) * 100
    
    # categorize discordance
    discordance_levels <- table(
        state_wval[!comparison_df$Match], 
        nwss_wval[!comparison_df$Match]
    )
    
    # print summary
    cat("Concordance Analysis:\n")
    cat("Total observations:", total_obs, "\n")
    cat("Concordant observations:", matching_obs, "\n")
    cat("Discordant observations:", non_matching_obs, "\n")
    cat("Concordance percentage:", round(match_percentage, 2), "%\n")
    cat("Discordance percentage:", round(discordance_percentage, 2), "%\n\n")
    
    # create contingency table of all observations
    cont_table <- table(state_wval, nwss_wval)
    cat("Contingency Table (Counts):\n")
    print(cont_table)
    
    # print discordance details if there are mismatches
    if (non_matching_obs > 0) {
        cat("\nDiscordance Details:\n")
        cat("Observations where categorizations differ:\n")
        print(discordance_levels)
        
        # discordance analysis
        cat("\nDetailed Discordance Analysis:\n")
        # calculate how far apart the mismatched categories are
        discordance_distance <- sapply(which(!comparison_df$Match), function(i) {
            abs(as.numeric(state_wval[i]) - as.numeric(nwss_wval[i]))
        })
        
        cat("Discordance Category Distance Distribution:\n")
        print(table(discordance_distance))
    }
    
    # return comparison dataframe invisibly
    invisible(comparison_df)
}
```



# CA Example of Comparing WVAL Outputs between CDC and your jurisdiction
```{r read in NWSS jurisdiction wvals}

# NWSS State WVAL from website
nwss_wvals_sarscov2 <- read_csv("https://www.cdc.gov/wcms/vizdata/NCEZID_DIDRI/SC2/nwsssc2stateactivitylevelDL.csv")

# Filter for jurisdiction
nwss_juris_wvals_sarscov2 <- nwss_wvals_sarscov2 %>%
  mutate(Week_Ending_Date = as.Date(lubridate::parse_date_time(Week_Ending_Date, orders = c("mdY", "Ymd")))) %>%
  # select for jurisdiction being tested
  filter(`State/Territory` == 'California') %>%
  filter(Data_Collection_Period == "All Results") %>%
  rename(week_end = Week_Ending_Date,
         nwss_state_wval = `State/Territory_WVAL`,
         nwss_state_level = WVAL_Category) %>%
  select(week_end, nwss_state_wval, nwss_state_level)

state_wval_sarscov2 <- state_wval_sarscov2 %>%
  left_join(nwss_juris_wvals_sarscov2, by = c("week_end"))

nwss_wvals_flu <- read_csv("https://www.cdc.gov/wcms/vizdata/NCEZID_DIDRI/FluA/nwssfluastateactivitylevelDL.csv")

nwss_juris_wvals_flu <- nwss_wvals_flu %>%
  mutate(Week_Ending_Date = as.Date(lubridate::parse_date_time(Week_Ending_Date, orders = c("mdY", "Ymd")))) %>%
  # select for jurisdiction being tested
  filter(`State/Territory` == 'California') %>%
  filter(Data_Collection_Period == "All Results") %>%
  rename(week_end = Week_Ending_Date,
         nwss_state_wval = `State/Territory_WVAL`,
         nwss_state_level = WVAL_Category) %>%
  select(week_end, nwss_state_wval, nwss_state_level)

state_wval_flu  <- state_wval_flu %>%
  left_join(nwss_juris_wvals_flu, by = c("week_end"))

nwss_wvals_rsv <- read_csv("https://www.cdc.gov/wcms/vizdata/NCEZID_DIDRI/rsv/nwssrsvstateactivitylevel.csv")

nwss_juris_wvals_rsv <- nwss_wvals_rsv %>%
  mutate(Week_Ending_Date = as.Date(lubridate::parse_date_time(Week_Ending_Date, orders = c("mdY", "Ymd")))) %>%
  # select for jurisdiction being tested
  filter(`State/Territory` == 'California') %>%
  filter(Data_Collection_Period == "All Results") %>%
  rename(week_end = Week_Ending_Date,
         nwss_state_wval = `State/Territory_WVAL`,
         nwss_state_level = WVAL_Category) %>%
  select(week_end, nwss_state_wval, nwss_state_level)

state_wval_rsv  <- state_wval_rsv %>%
  left_join(nwss_juris_wvals_rsv, by = c("week_end"))

# Combine
rv_state_wvals <- bind_rows(state_wval_sarscov2, state_wval_flu, state_wval_rsv)
```

```{r plot wvals}
ggplot(state_wval_sarscov2, aes(x = week_end)) +
  geom_line(aes(y = state_wval), color = "black") +
  geom_line(aes(y = nwss_state_wval), color = "purple3") +
  ggtitle("State SARS-CoV-2 WVAL (Purple: NWSS WVAL)")

ggplot(state_wval_flu, aes(x = week_end)) +
  geom_line(aes(y = state_wval), color = "black") +
  geom_line(aes(y = nwss_state_wval), color = "purple3") +
  ggtitle("State Influenza A WVAL (Purple: NWSS WVAL)")

ggplot(state_wval_rsv, aes(x = week_end)) +
  geom_line(aes(y = state_wval), color = "black") +
  geom_line(aes(y = nwss_state_wval), color = "purple3") +
  ggtitle("State RSV WVAL (Purple: NWSS WVAL)")
```

# wval datasets compare
```{r}
# Prep to compare: remove weeks missing nwss wval
rv_state_wval_filter <- rv_state_wvals %>%
  filter(!is.na(nwss_state_level))

state_wval_sarscov2 <- state_wval_sarscov2 %>%
  filter(!is.na(nwss_state_level))

state_wval_flu <- state_wval_flu %>%
  filter(!is.na(nwss_state_level))

state_wval_rsv <- state_wval_rsv %>%
  filter(!is.na(nwss_state_level))

# If you don't have NWSS site wvals, compare state levels
# Overall concordance for all three pathogens
compare_wval_function(state_wval = rv_state_wval_filter$state_level, nwss_wval = rv_state_wval_filter$nwss_state_level)

# Sars-CoV-2 concordance
compare_wval_function(state_wval = state_wval_sarscov2$state_level, nwss_wval = state_wval_sarscov2$nwss_state_level)

# Influenza A concordance
compare_wval_function(state_wval = state_wval_flu$state_level, nwss_wval = state_wval_flu$nwss_state_level)

# RSV concordance
compare_wval_function(state_wval = state_wval_rsv$state_level, nwss_wval = state_wval_rsv$nwss_state_level)
```
